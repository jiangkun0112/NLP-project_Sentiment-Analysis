{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Sentiment Analysis\n",
    "\n",
    "**Author: Kun Jiang (kunjiang0112@gmail.com)**\n",
    "\n",
    "This project addresses the problem of sentiment analysis in IMDB movie reviews by classifying movie comments according to the sentiment expressed in them: \"positive\" or \"negative\". The purpose of this project is to describe the process to develop a automatic classifier using machine learning and deep learning algorithms for accurate sentiment classification of an unknown IMDB movie comment. \n",
    "\n",
    "In this notebook, I use different packages in Python to build a complete pipeline for solving sentiment analysis problem\n",
    "\n",
    "**Outline:**\n",
    "\n",
    "- Load Dataset\n",
    "\n",
    "- Feature Extraction\n",
    "    * Count Vectorizer\n",
    "    * Tf-idf\n",
    "\n",
    "- Classification Models\n",
    "    * Naive Bayes \n",
    "    * Supported Vector Machine(SVM)\n",
    "    * Tf-idf + Logistic Regression\n",
    "    * Deep Learning (CNN & LSTM)\n",
    "    \n",
    "    \n",
    "Make sure the following enviroment and packages are installed:\n",
    "\n",
    "- anaconda3 w/ python 3.6\n",
    "- scikit-learn\n",
    "- tensorflow\n",
    "- keras\n",
    "- nltk\n",
    "- pandas, numpy, matplotlib\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "\n",
    "The Movie Review Data is a collection of movie reviews retrieved from the imdb.com website. You can download the dataset from here:\n",
    "\n",
    "Large Movie Review Dataset http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "The dataset provides a set of 25,000 highly polar movie reviews for training (train.csv), and 25,000 for testing (test.csv). Raw text and already processed bag of words formats are provided.\n",
    "\n",
    "Next, let’s look at loading and preparing the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv file into DataFrame\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment  : pos\n",
      "reviewText : For a movie that gets no respect there sure are a lot of memorable quotes listed for this gem. Imagine a movie where Joe Piscopo is actually funny! Maureen Stapleton is a scene stealer. The Moroni character is an absolute scream. Watch for Alan \"The Skipper\" Hale jr. as a police Sgt.\n"
     ]
    }
   ],
   "source": [
    "print(\"sentiment  :\", train.sentiment[0])\n",
    "print(\"reviewText :\", train.reviewText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText sentiment\n",
       "0  For a movie that gets no respect there sure ar...       pos\n",
       "1  Bizarre horror movie filled with famous faces ...       pos\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...       pos\n",
       "3  It's a strange feeling to sit alone in a theat...       pos\n",
       "4  You probably all already know this by now, but...       pos"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a sample (head) of the data frame\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neg    12500\n",
       "pos    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Statics on tags\n",
    "train.sentiment.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(train.sentiment.unique(), train.sentiment.value_counts())\n",
    "plt.xlabel('Sentiment Level')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment level distribution in train data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEWCAYAAACufwpNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAHa5JREFUeJzt3X+cXfO97/HXu4n4XYmaupGE0SMHiZZDBEXriEOiP6K9fsRxK8iVw6GnaKtUe9Iipzxu70GPolGp0BbhcAUpcvxqiyDUrwiS41emCYYkxG/hc/9Y383K2DN7Z/Kd2ca8n4/Hfsxa3/Vda33W3nv2e9aPvUYRgZmZWQ6fanQBZmb2yeFQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWLtknSBpB83uo5qJD0jaa8uXsfFkk6vs2+zpJDUN43/QdL4THXsLumJ0njWbZc0V9IeuZZXWm6256A7SfqJpN82uo6eyqHSw0jaTdJdkl6RtETSnZJ2zLDcwyT9udwWEUdFxGmru+xO1NLjf6kjYkxETKvVLwXRFjWW9aeI2DJHXdWCMiKGR8TtOZbfZrl1PQfV5ArOau/rnFblD4/eom+jC7D6Sfo0cD1wNDAd6AfsDrzdyLqs60jqGxErGl2HWd0iwo8e8gBGAMtq9DkCmAcsBW4CNitNC+AoYH6a/ktAwNbAW8B7wGuVdQAXA6en4T2AFuBE4EVgMbAfsC/wJLAE+GFpXZ8CTgL+G3iZIgQ3TNOaUy3jgeeAl4BT0rTRwDvAu6mWh9rZzmeAvepY143AsW3mfQj4ZhreCpiV6n8COLDU74Ptr7L+PsDPU+1PAcekbeqbpt8O/O80vAVwB/BK6n9Fav9jmuf1tK0HlZ7nHwDPA5dW2tps+8nAY+l1/A2wVpp2GPDnNrVGqmFiel7fSeu7rspzuSZwNrAoPc4G1mzzHvhu6T1weAfvxfJzcBjw5/ScLQWeBsa0M9+lwPvAm6nOE1P7zsBdwLL0Gu5Rmuew9DosT8s+hHbe11XWt3l6fZan98K5wG9L069Mr8Ur6TUbntrbez4r78Xl6TX6RqM/O7rz0fAC/FiFFws+TfGhOQ0YAwxoM30/YEH6ZeoL/Ai4qzQ9KPZ0+gObAq3A6DSt2ofRxawcKiuAfwXWAI5M8/8eWB8Ynn6BP5f6HwfMBganD6pfAZelac2plguBtYFtKfa2tk7Tf1L+pW7nuXiGDz8IO1rXocCdpfmGpQ+lNYF1gYXA4en52p7iQ3942+2vsv6jgMeBIcCGwG20HyqXAadQhN9awG5tXpMtSuOV5/nMVOPaVA+VR0vrvrP0OlV7HT9YR7VtavNcnpqey88CTRQf4qe1qe3U9B7YF3iDNu/D0nLLz8FhFB/AR1IE8tEUoaVar28aH0Tx3t83PY//kMab0uv4KrBl6juw9Bp+5Pmosq67gX9Pz/eXKMKgHCpHULzHK4H7YLXfkVLbAcAmqc6DKP5oGNjoz4/uevicSg8SEa8Cu/HhB3KrpBmSNk5d/gn4WUTMi+KQyb8B20narLSYMyJiWUQ8R/FBuN0qlPAuMDki3gUuBzYCzomI5RExF5gLfKFUyykR0RIRb1MExf6VE9nJTyPizYh4iOIvz21XoZayjtZ1DSs/B4cAV6d+XwWeiYjfRMSKiHgA+E9g/zrWeSBwdkQsjIglwM866PsusBmwSUS8FRG1jvG/D0yKiLcj4s12+pxbWvdk4OA6aq7HIcCpEfFiRLQCPwW+VZr+bpr+bkTMpPgLvd7zPc9GxIUR8R7FH0YDgY1rzFPxv4CZETEzIt6PiFnAHIqQgeI520bS2hGxOL0fa5K0KbAj8OP0fP8RuK7cJyKmpvd45b21raQN2ltmRFwZEYtSnVdQHBkYWed29ngOlR4mBcZhETEY2IbiL6Kz0+TNgHMkLZO0jOKQjij+yqt4vjT8BrDeKqz+5fSBAMWhCYAXStPfLC1vM+CaUi3zKA5DlD9EVqeWsnbXFRHLgRuAcanvOOB3pfl2qsyX5j0E+B91rHMTir2cimc76Hsixetwb7rS6ogay26NiLdq9Gm77k1q9K/XJqy8LW2X/XKsfI5nVV63D17viHgjDdY772bAAW1eq90o9gBep9gjOApYLOkGSVvVudxNgKVpGRUfbL+kPpLOkPTfkl6l2IOC4g+qqiQdKunBUp3bdNT/k8ah0oNFxOMUu9/bpKaFwD9FRP/SY+2IuKuexWUubyHFMfNyLWtFxF+7oJZa67oMOFjSLhSHk24rzXdHm/nWi4ij61jnYorDTxWbtrsxEc9HxJERsQnFXtV5Na74qmf72657URp+HVinMkFS24CstexFFB/g1ZbdndrWuRC4tM1rtW5EnAEQETdFxD9Q7P08TrEnX205bS0GBkhat9RWfi3/ERgL7AVsQHHoFoo/Ej6y/LRHfCFwLPCZiOhPcahS9BIOlR5E0laSvitpcBofQnHYY3bqcgFwsqThafoGkg6oc/EvAIMl9ctU7gXA5MphJ0lNksauQi3Nkup9f9Za10yKD8pTKU6Sv5/arwf+VtK3JK2RHjtK2rqOdU4H/kXSYEkDKE7OViXpgMprRnGSOij2pCrb+rk6t7PsmLTuDYEfAlek9oeA4ZK2k7QWxeGaslrruwz4UXoON6I4h9aIy7vb1vlb4GuS9kl7D2tJ2iM9BxtL+noKhrcpDsmVn99239cR8SzFYbSfSuonaTfga6Uu66dlvkwR1v9Wo851KV7fVgBJh/PhH329gkOlZ1kO7ATcI+l1ijB5lOJqHCLiGooTvJenXfVHKU7o1+NWinMiz0t6KUOt5wAzgJslLU+17lTnvFemny9LemB115WOhV9N8dfm70vty4G9KQ6JLaI4PFM5QV7LhRRX1z0EPJCW354dKV6z11Kd34mIp9O0nwDT0qGSA+tYb8XvgZsprnh6Cjg9bdOTFOH5XxTH8tuev7kIGJbW9/+qLPd0ig/Zh4FH0rY14nsYP6MIt2WSvhcRCyn2GH5I8YG9EPg+xWfYpyh+BxZRHPL9MvDPaTn1vK//keL9sgSYBFxSmnYJxeGwv1JcyTW7zbwrPZ8R8RjwfylO/r8AfJ7iQopeQxH+J11mZpaH91TMzCwbh4qZmWXjUDEzs2wcKmZmlk2vu6HkRhttFM3NzY0uw8ysR7n//vtfioimWv16Xag0NzczZ86cRpdhZtajSOrorhEf8OEvMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLptd9o351NJ90Q6NLsI+pZ874SqNLAPwetfZ113vUeypmZpaNQ8XMzLJxqJiZWTYOFTMzy6bLQkXSVEkvSnq01PZ/JD0u6WFJ10jqX5p2sqQFkp6QtE+pfXRqWyDppFL75pLukTRf0hWS+nXVtpiZWX26ck/lYmB0m7ZZwDYR8QXgSeBkAEnDgHHA8DTPeZL6SOoD/BIYAwwDDk59Ac4EzoqIocBSYEIXbouZmdWhy0IlIv4ILGnTdnNErEijs4HBaXgscHlEvB0RTwMLgJHpsSAinoqId4DLgbGSBOwJXJXmnwbs11XbYmZm9WnkOZUjgD+k4UHAwtK0ltTWXvtngGWlgKq0VyVpoqQ5kua0trZmKt/MzNpqSKhIOgVYAfyu0lSlW3SivaqImBIRIyJiRFNTzX+xbGZmndTt36iXNB74KjAqIipB0AIMKXUbDCxKw9XaXwL6S+qb9lbK/c3MrEG6dU9F0mjgB8DXI+KN0qQZwDhJa0raHBgK3AvcBwxNV3r1oziZPyOF0W3A/mn+8cC13bUdZmZWXVdeUnwZcDewpaQWSROAc4H1gVmSHpR0AUBEzAWmA48BNwLHRMR7aS/kWOAmYB4wPfWFIpxOkLSA4hzLRV21LWZmVp8uO/wVEQdXaW73gz8iJgOTq7TPBGZWaX+K4uowMzP7mPA36s3MLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtl0WahImirpRUmPlto2lDRL0vz0c0Bql6RfSFog6WFJ25fmGZ/6z5c0vtS+g6RH0jy/kKSu2hYzM6tPV+6pXAyMbtN2EnBLRAwFbknjAGOAoekxETgfihACJgE7ASOBSZUgSn0mluZruy4zM+tmXRYqEfFHYEmb5rHAtDQ8Ddiv1H5JFGYD/SUNBPYBZkXEkohYCswCRqdpn46IuyMigEtKyzIzswbp7nMqG0fEYoD087OpfRCwsNSvJbV11N5Spb0qSRMlzZE0p7W1dbU3wszMqvu4nKivdj4kOtFeVURMiYgRETGiqampkyWamVkt3R0qL6RDV6SfL6b2FmBIqd9gYFGN9sFV2s3MrIG6O1RmAJUruMYD15baD01Xge0MvJIOj90E7C1pQDpBvzdwU5q2XNLO6aqvQ0vLMjOzBunbVQuWdBmwB7CRpBaKq7jOAKZLmgA8BxyQus8E9gUWAG8AhwNExBJJpwH3pX6nRkTl5P/RFFeYrQ38IT3MzKyBuixUIuLgdiaNqtI3gGPaWc5UYGqV9jnANqtTo5mZ5fVxOVFvZmafAA4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsmlIqEg6XtJcSY9KukzSWpI2l3SPpPmSrpDUL/VdM40vSNObS8s5ObU/IWmfRmyLmZl9qNtDRdIg4F+AERGxDdAHGAecCZwVEUOBpcCENMsEYGlEbAGclfohaViabzgwGjhPUp/u3BYzM1tZow5/9QXWltQXWAdYDOwJXJWmTwP2S8Nj0zhp+ihJSu2XR8TbEfE0sAAY2U31m5lZFd0eKhHxV+DnwHMUYfIKcD+wLCJWpG4twKA0PAhYmOZdkfp/ptxeZZ6VSJooaY6kOa2trXk3yMzMPtCIw18DKPYyNgc2AdYFxlTpGpVZ2pnWXvtHGyOmRMSIiBjR1NS06kWbmVldGnH4ay/g6YhojYh3gauBLwL90+EwgMHAojTcAgwBSNM3AJaU26vMY2ZmDdCIUHkO2FnSOuncyCjgMeA2YP/UZzxwbRqekcZJ02+NiEjt49LVYZsDQ4F7u2kbzMysir61u+QVEfdIugp4AFgB/AWYAtwAXC7p9NR2UZrlIuBSSQso9lDGpeXMlTSdIpBWAMdExHvdujFmZraSbg8VgIiYBExq0/wUVa7eioi3gAPaWc5kYHL2As3MrFP8jXozM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWTV2hImnXetrMzKx3q3dP5T/qbDMzs16swy8/StqF4r5cTZJOKE36NMX/QTEzM/tArW/U9wPWS/3WL7W/yof36TIzMwNqhEpE3AHcIeniiHi2m2oyM7Meqt57f60paQrQXJ4nIvbsiqLMzKxnqjdUrgQuAH4N+E7AZmZWVb2hsiIizu/SSszMrMer95Li6yT9s6SBkjasPLq0MjMz63Hq3VOp/OfF75faAvhc3nLMzKwnqytUImLzri7EzMx6vrpCRdKh1doj4pK85ZiZWU9W7+GvHUvDawGjKP7HvEPFzMw+UO/hr2+XxyVtAFzaJRWZmVmP1dlb378BDM1ZiJmZ9Xz1nlO5juJqLyhuJLk1ML2rijIzs56p3nMqPy8NrwCejYiWLqjHzMx6sLoOf6UbSz5OcafiAcA7XVmUmZn1TPX+58cDgXuBA4ADgXskdfrW95L6S7pK0uOS5knaJX1Lf5ak+enngNRXkn4haYGkhyVtX1rO+NR/vqTx7a/RzMy6Q70n6k8BdoyI8RFxKDAS+PFqrPcc4MaI2ArYFpgHnATcEhFDgVvSOMAYiosChgITgfMB0m1iJgE7pXomVYLIzMwao95Q+VREvFgaf3kV5l2JpE8DXwIuAoiIdyJiGTAWmJa6TQP2S8NjgUuiMBvoL2kgsA8wKyKWRMRSYBYwujM1mZlZHvWeqL9R0k3AZWn8IGBmJ9f5OaAV+I2kbYH7ge8AG0fEYoCIWCzps6n/IGBhaf6W1NZe+0dImkixl8Omm27aybLNzKyWDvc2JG0hadeI+D7wK+ALFIer7gamdHKdfYHtgfMj4u+A1/nwUFfVMqq0RQftH22MmBIRIyJiRFNT06rWa2Zmdap1COtsYDlARFwdESdExPEUeylnd3KdLUBLRNyTxq+iCJkX0mEt0s8XS/2HlOYfDCzqoN3MzBqkVqg0R8TDbRsjYg7FvxZeZRHxPLBQ0papaRTwGDCDD2+xPx64Ng3PAA5NV4HtDLySDpPdBOwtaUA6Qb93ajMzswapdU5lrQ6mrb0a6/028DtJ/YCngMMpAm66pAnAcxSXL0OxV7QvsIDi9jCHA0TEEkmnAfelfqdGxJLVqMnMzFZTrVC5T9KREXFhuTF98N/f2ZVGxIPAiCqTRlXpG8Ax7SxnKjC1s3WYmVletULlOOAaSYfwYYiMAPoB3+jKwszMrOfpMFQi4gXgi5L+HtgmNd8QEbd2eWVmZtbj1Pv/VG4DbuviWszMrIfr7P9TMTMz+wiHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyycaiYmVk2DhUzM8vGoWJmZtk4VMzMLBuHipmZZeNQMTOzbBwqZmaWjUPFzMyyaVioSOoj6S+Srk/jm0u6R9J8SVdI6pfa10zjC9L05tIyTk7tT0japzFbYmZmFY3cU/kOMK80fiZwVkQMBZYCE1L7BGBpRGwBnJX6IWkYMA4YDowGzpPUp5tqNzOzKhoSKpIGA18Bfp3GBewJXJW6TAP2S8Nj0zhp+qjUfyxweUS8HRFPAwuAkd2zBWZmVk2j9lTOBk4E3k/jnwGWRcSKNN4CDErDg4CFAGn6K6n/B+1V5jEzswbo9lCR9FXgxYi4v9xcpWvUmNbRPG3XOVHSHElzWltbV6leMzOrXyP2VHYFvi7pGeByisNeZwP9JfVNfQYDi9JwCzAEIE3fAFhSbq8yz0oiYkpEjIiIEU1NTXm3xszMPtDtoRIRJ0fE4IhopjjRfmtEHALcBuyfuo0Hrk3DM9I4afqtERGpfVy6OmxzYChwbzdthpmZVdG3dpdu8wPgckmnA38BLkrtFwGXSlpAsYcyDiAi5kqaDjwGrACOiYj3ur9sMzOraGioRMTtwO1p+CmqXL0VEW8BB7Qz/2RgctdVaGZmq8LfqDczs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2wcKmZmlo1DxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2y6PVQkDZF0m6R5kuZK+k5q31DSLEnz088BqV2SfiFpgaSHJW1fWtb41H++pPHdvS1mZrayRuyprAC+GxFbAzsDx0gaBpwE3BIRQ4Fb0jjAGGBoekwEzocihIBJwE7ASGBSJYjMzKwxuj1UImJxRDyQhpcD84BBwFhgWuo2DdgvDY8FLonCbKC/pIHAPsCsiFgSEUuBWcDobtwUMzNro6HnVCQ1A38H3ANsHBGLoQge4LOp2yBgYWm2ltTWXnu19UyUNEfSnNbW1pybYGZmJQ0LFUnrAf8JHBcRr3bUtUpbdND+0caIKRExIiJGNDU1rXqxZmZWl4aEiqQ1KALldxFxdWp+IR3WIv18MbW3AENKsw8GFnXQbmZmDdKIq78EXATMi4h/L02aAVSu4BoPXFtqPzRdBbYz8Eo6PHYTsLekAekE/d6pzczMGqRvA9a5K/At4BFJD6a2HwJnANMlTQCeAw5I02YC+wILgDeAwwEiYomk04D7Ur9TI2JJ92yCmZlV0+2hEhF/pvr5EIBRVfoHcEw7y5oKTM1XnZmZrQ5/o97MzLJxqJiZWTYOFTMzy8ahYmZm2ThUzMwsG4eKmZll41AxM7NsHCpmZpaNQ8XMzLJxqJiZWTYOFTMzy8ahYmZm2ThUzMwsG4eKmZll41AxM7NsHCpmZpaNQ8XMzLJxqJiZWTYOFTMzy8ahYmZm2ThUzMwsG4eKmZll41AxM7NsHCpmZpZNjw8VSaMlPSFpgaSTGl2PmVlv1qNDRVIf4JfAGGAYcLCkYY2tysys9+rRoQKMBBZExFMR8Q5wOTC2wTWZmfVafRtdwGoaBCwsjbcAO7XtJGkiMDGNvibpiW6orTfYCHip0UV8HOjMRldg7fB7NMnwHt2snk49PVRUpS0+0hAxBZjS9eX0LpLmRMSIRtdh1h6/R7tfTz/81QIMKY0PBhY1qBYzs16vp4fKfcBQSZtL6geMA2Y0uCYzs16rRx/+iogVko4FbgL6AFMjYm6Dy+pNfEjRPu78Hu1mivjIKQgzM7NO6emHv8zM7GPEoWJmZtk4VMzMLBuHipmZZeNQsXZJapb0uKRpkh6WdJWkdSSNkvQXSY9ImippzdT/DEmPpb4/b3T99smW3p/zJF0oaa6kmyWtLelvJN0o6X5Jf5K0Ver/N5JmS7pP0qmSXmv0NnwSOVSsli2BKRHxBeBV4ATgYuCgiPg8xWXpR0vaEPgGMDz1Pb1B9VrvMhT4ZUQMB5YB/5PiMuJvR8QOwPeA81Lfc4BzImJH/CXpLuNQsVoWRsSdafi3wCjg6Yh4MrVNA75EEThvAb+W9E3gjW6v1HqjpyPiwTR8P9AMfBG4UtKDwK+AgWn6LsCVafj33Vlkb9Kjv/xo3aKuLzKlL6KOpAidccCxwJ5dWZgZ8HZp+D1gY2BZRGzXoHp6Pe+pWC2bStolDR8M/BfQLGmL1PYt4A5J6wEbRMRM4DjAv9TWCK8CT0s6AECFbdO02RSHx6D4w8e6gEPFapkHjJf0MLAhcBZwOMXhhUeA94ELgPWB61O/O4DjG1Sv2SHABEkPAXP58H8sHQecIOleikNirzSovk8036bF2iWpGbg+IrZpcClmq03SOsCbERGSxgEHR4T/qV9mPqdiZr3FDsC5kkRxpdgRDa7nE8l7KmZmlo3PqZiZWTYOFTMzy8ahYmZm2ThUrFeRdEq6T9TDkh6UtFMnl7OdpH1L41+XdFK+Squucw9JX2xn2mGSzu3Cdd8uaURXLd8+OXz1l/Ua6UucXwW2j4i3JW0E9Ovk4rYDRgAzASJiBjAjS6Ht2wN4Dbiri9dj1mneU7HeZCDwUkS8DRARL0XEIgBJO0i6I93Z9iZJA1P77ZLOlHSvpCcl7S6pH3AqcFDa2zmovKcg6WJJ50u6TdJTkr6c7uY8T9LFlWIk7S3pbkkPSLoy3ZUASc9I+mlqf0TSVuk7Q0cBx6d17l7PBldbh6QxkqaX+uwh6bqOajKrl0PFepObgSEpHM6T9GUASWsA/wHsn+5sOxWYXJqvb0SMpPhG9qSIeAf4V+CKiNguIq6osq4BFPc+Ox64juJOBMOBz6dDZxsBPwL2iojtgTkUd4CueCm1nw98LyKeobhzwVlpnX+qtbEdrGMWsLOkdVPXg4Ar6qjJrCYf/rJeIyJek7QDsDvw9xQfpCdRfHhuA8wqvhdHH2Bxadar08/KXXDrcV365vYjwAsR8QiApLlpGYOBYcCdaZ39gLvbWec369/KlexcbR3p5p83Al+TdBXwFeBE4Ms1ajKryaFivUpEvAfcDtyePvDHU3xwz42IXdqZrXIn3Peo/3emMs/7rHwn3ffTMt4DZkXEwRnX2ZY6WMcVwDHAEuC+iFievmneUU1mNfnwl/UakraUNLTUtB3wLPAE0FS5G7OkNSQNr7G45RQ30eys2cCulbs9q/iPmn+beZ0dreN2YHvgSIqA6WxNZitxqFhvsh4wTelfHlMc6vlJOkeyP3BmurPtgxT/6KkjtwHDKifqV7WQiGgFDgMuS7XMBraqMdt1wDc6OFF/mKSWygNYs711pD2264Ex6WdnazJbie/9ZWZm2XhPxczMsnGomJlZNg4VMzPLxqFiZmbZOFTMzCwbh4qZmWXjUDEzs2z+P7U4rjU5HvrjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(test.sentiment.unique(), test.sentiment.value_counts())\n",
    "plt.xlabel('Sentiment Level')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment level distribution in test data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data in to List\n",
    "\n",
    "Loading dataset into list helps the processsing of movie reivews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    x = data['reviewText'].tolist()\n",
    "    y = data['sentiment'].tolist()\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_data('train.csv')\n",
    "test_x, test_y = load_data('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training size: 25000\n",
      "test size: 25000\n"
     ]
    }
   ],
   "source": [
    "print('training size:', len(train_x))\n",
    "print('test size:', len(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Cleaning the document involves splitting each review based on white space, removing punctuation, and then filtering out all tokens not in the vocabulary.\n",
    "\n",
    "- Just looking at the raw tokens can give us a lot of ideas of things to try, such as:\n",
    "    * Lematize tokens (e.g. 'drive, drove, drived' --> 'driv')\n",
    "    * Remove punctuation from words (e.g. ‘what’s’,  ‘-‘). We can filter out punctuation from tokens using the string translate() function.\n",
    "    * Removing tokens that are just stop words and don't have much meanings (e.g. 'I', 'you', 'me', ‘and’). We can remove stop words using the list loaded using NLTK.\n",
    "    * Removing tokens that are numbers (e.g. ’10′).\n",
    "    * Remove tokens that don’t have much meaning (e.g.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "transtbl = str.maketrans(string.punctuation, ' ' * len(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing() function treat a line of comment by removing html tag, converting to lower case, \n",
    "# splitting each review based on white space, removing punctuation\n",
    "def preprocessing(line):\n",
    "    line = line.replace('<br />', '')   # Remove html tag (<br />)\n",
    "    line = line.translate(transtbl)     # Remove punctuation\n",
    "    \n",
    "    # Get tokens\n",
    "    tokens = []\n",
    "    for t in nltk.word_tokenize(line):\n",
    "        t = t.lower()\n",
    "        if t not in stopwords:\n",
    "            lemma = lemmatizer.lemmatize(t, 'v')\n",
    "            tokens.append(lemma)\n",
    "            \n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buy several book yesterday really love'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_str = \"I bought several books yesterday<br /> and I really love them!\"\n",
    "preprocessing(test_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess both train and test data \n",
    "train_x = [preprocessing(x) for x in train_x]\n",
    "test_x = [preprocessing(x) for x in test_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary\n",
    "\n",
    "Before running the model, it is important to build a vocabulary of known words when using a bag-of-words or embedding model. We can develop a vocabulary as a Counter, which is a dictionary mapping of words and their counts that allow us to easily update and query. The more words, the larger the representation of documents, therefore it is important to constrain the words to only those believed to be predictive.\n",
    "\n",
    "nltk provides a simple function to build a covabulary called FreqDist(), which will be used in this part. Each review can be added to the counter and we can step over all of the reviews in the train and test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push all tokens and compute frequency of words\n",
    "all_words = []\n",
    "for line in train_x:\n",
    "    words = line.split()\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "for line in test_x:\n",
    "    words = line.split()\n",
    "    for w in words:\n",
    "        all_words.append(w)\n",
    "        \n",
    "voca = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91654"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('film', 95792),\n",
       " ('movie', 87752),\n",
       " ('one', 53514),\n",
       " ('make', 46110),\n",
       " ('like', 44237),\n",
       " ('see', 41568),\n",
       " ('get', 35666),\n",
       " ('time', 31864),\n",
       " ('good', 29703),\n",
       " ('character', 28299)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preview the most common 10 words\n",
    "voca.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are a little over 91,000 unique words across all reviews and the top 10 words are ‘film‘, 'movie', ‘one‘, 'make', 'like', 'see', 'get', 'time', 'good', 'character'.  \n",
    "\n",
    "Generally, words that only appear once or a few times are probably not predictive and can be removed from the vocabulary, greatly cutting down on the tokens we need to model. We can remove the less-frequent words by selecting the top 10000 words. We can then save the chosen vocabulary of words to a new list called topwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 10, 000 words\n",
    "topwords = [fpair[0] for fpair in list(voca.most_common(10000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt_vec = CountVectorizer()\n",
    "cnt_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our BAG of words (specify words we care about)\n",
    "cnt_vec.fit(topwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tf–idf \n",
    "\n",
    "- Tf: term-frequency\n",
    "- idf: inverse document-frequency\n",
    "- Tf-idf = $tf(t,d) \\times idf(t)$\n",
    "\n",
    "TF-IDF stands for Term frequency inverse document frequency, is a statistical measure to see how important the appearance of a word in a document corpus is for classification. Term frequency measures how many times a term has appeared in a particular document, and inverse document frequency measures logarithm inverse of number of ducuments that have that word out of total number of documents. Augmented TF-IDF is used to avoid bias towards longer documents, and it is defined as below for a term $t$ appearing in a particular document $d$:\n",
    "\n",
    "$$ TF(t, d) = 0.5 + \\frac{0.5 \\times freq(t, d)}{max(freq(w, d) \\ \\ where\\  w \\in d)} $$$$IDF(t, D_{train}) = \\frac{|D_{train}|}{|\\{d\\in D_{train} \\ \\ where\\  t \\in d\\}|}$$\n",
    "and\n",
    "\n",
    "$$TFIDF(t, d, D) = TF(t,d) \\times IDF(t, d)$$\n",
    "where $D_{train}=\\{set\\ of\\ all\\ training\\ documents\\}$. It is important to note that TF-IDF depends on the entire set of documents that we are considering (for example the training set), and not just the term in a document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vec = TfidfVectorizer()\n",
    "tf_vec.fit(topwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features from training set\n",
    "# Vocabulary is from topwords\n",
    "tf_vec = TfidfVectorizer(vocabulary=topwords)\n",
    "train_features = tf_vec.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 10000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = tf_vec.transform(test_x)\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1: Naive Bayes\n",
    "Naive bayes is a popular algorithm for classifying text. Although it is fairly simple, it often performs as well as much more complicated solutions. We will start to build a Naive Bayes model, which will be used as a baseline in our prediction. \n",
    "\n",
    "### [Multinomial NB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n",
    "\n",
    "We will be using Mutinomial Naive Bayes in this section.The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model = MultinomialNB()\n",
    "mnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB model trained in 0.025601 seconds\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "mnb_model.fit(train_features, train_y)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Multinomial NB model trained in %f seconds\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'pos' ... 'neg' 'neg' 'neg']\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "pred = mnb_model.predict(test_features)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83284\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "# metrics.accuracy_score(y_true, y_pred)\n",
    "from sklearn import metrics\n",
    "accuracy = metrics.accuracy_score(pred,test_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.81      0.86      0.84     12500\n",
      "        pos       0.86      0.80      0.83     12500\n",
      "\n",
      "avg / total       0.83      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use keyword arguments to set arguments explicitly\n",
    "print(metrics.classification_report(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the best topwords number with Word Count and Tf-idf\n",
    "\n",
    "since we have the basic model built with Naive Bayes, we can also optimize the number of topwords with the best performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_n_topwords(n: int, tfidf=False) -> tuple:\n",
    "    \"\"\"\n",
    "    Train and get the accuracy with different model settings\n",
    "    Args:\n",
    "        n: number of features (top frequent words in the vocabulary)\n",
    "        tfidf: whether do tf-idf re-weighting or not\n",
    "    Outputs:\n",
    "        tuple: (accuracy score, classifier, vectorizer)\n",
    "    \"\"\"\n",
    "    topwords = [fpair[0] for fpair in list(voca.most_common(n))]\n",
    "    \n",
    "    if tfidf:\n",
    "        vec = TfidfVectorizer(vocabulary=topwords)\n",
    "    else:\n",
    "        vec = CountVectorizer(vocabulary=topwords)\n",
    "    \n",
    "    # Generate feature vectors\n",
    "    train_features = vec.fit_transform(train_x)\n",
    "    test_features  = vec.transform(test_x)\n",
    "    \n",
    "    # NB\n",
    "    mnb_model = MultinomialNB()\n",
    "    mnb_model.fit(train_features, train_y)\n",
    "    \n",
    "    # Test predict\n",
    "    pred = mnb_model.predict(test_features)\n",
    "    \n",
    "    return metrics.accuracy_score(pred, test_y), mnb_model, vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_n = [500 * i for i in range(1, 20)]\n",
    "\n",
    "cnt_accuracies = []\n",
    "tfidf_accuracies = []\n",
    "\n",
    "for i, n in enumerate(possible_n):\n",
    "    cnt_accuracies.append(train_with_n_topwords(n)[0])\n",
    "   \n",
    "    tfidf_accuracies.append(train_with_n_topwords(n, tfidf=True)[0])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x54a9b70>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(possible_n, cnt_accuracies, label='Word Count')\n",
    "plt.plot(possible_n, tfidf_accuracies, label='Tf-idf')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best multinomial NB model (top_N = 3000)\n",
    "\n",
    "From previous step it can be found that the number of topwords at 3000 words gives the best performing model. \n",
    "Here we can save the multinominal NB mode and the vocabulary at 3000 topwords for modeling in the later stage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = train_with_n_topwords(3000, tfidf=True) # best = (acc, model, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.84      0.85      0.84     12500\n",
      "        pos       0.85      0.84      0.84     12500\n",
      "\n",
      "avg / total       0.84      0.84      0.84     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topwords = [fpair[0] for fpair in list(voca.most_common(3000))]\n",
    "tf_vec = TfidfVectorizer(vocabulary=topwords)\n",
    "train_features = tf_vec.fit_transform(train_x)\n",
    "test_features  = tf_vec.transform(test_x)\n",
    "\n",
    "best_mnb_model = best[1]\n",
    "pred = best_mnb_model.predict(test_features)\n",
    "print(metrics.classification_report(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After optimizing the size of the topwords, the NB model gives around 84% of accuracy using top 3000 words there is a slight improvement compared to the previous NB model (83%).\n",
    "\n",
    "Next, we need to save the vectonizer and the model trained at 3000 topwords for later usage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save vectorizer\n",
    "with open('tf_vec.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(best[2], pkl_file)\n",
    "\n",
    "with open('mnb_model.pkl', 'wb') as pkl_file:\n",
    "    pickle.dump(best[1], pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction result on the sample comment is: neg\n"
     ]
    }
   ],
   "source": [
    "sample = [\"this movie is bad\"]\n",
    "sample_features  = tf_vec.fit_transform(sample)\n",
    "sample_prediction = best_mnb_model.predict(sample_features)[0]\n",
    "print (\"the prediction result on the sample comment is: \" + sample_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SVM\n",
    "The Supported Vector Machine Classifier constructs a set of hyperplanes in a high dimensional space for classifications, trying to create a line that divides the dataset leaving the larger margin as possible between points called support vectors. In order to achieve a good classification, the distance from hyperplanes to the nearest training points should be maximized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to reload the td-idf vectornizer pretrained in the previous step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf_vec.pkl', 'rb') as fp:\n",
    "    tf_vec = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we need to reload the data from csv files, process them with the preprocessing() function and transform the train and test features using the tf-idf vectornizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_x, train_y = load_data('train.csv')\n",
    "test_x, test_y = load_data('test.csv')\n",
    "# preprocess\n",
    "train_x = [preprocessing(x) for x in train_x]\n",
    "test_x = [preprocessing(x) for x in test_x]\n",
    "# tf_idf transform\n",
    "train_features = tf_vec.fit_transform(train_x)\n",
    "test_features  = tf_vec.transform(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create our SVM classifier with the class LinearSVC and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC model trained in 0.536604 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "svm_model = LinearSVC()\n",
    "svm_model.fit(train_features, train_y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"LinearSVC model trained in %f seconds\" % (end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM prediction\n",
    "\n",
    "Make predictions on test data using the trained SVM model, generate the classification report and check the performance of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svm_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86528\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(pred,test_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.87      0.87      0.87     12500\n",
      "        pos       0.87      0.87      0.87     12500\n",
      "\n",
      "avg / total       0.87      0.87      0.87     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the score took less than 1 second only! Running the classifier we get around 87% of accuracy, which is slightly better than the result of the naive bayes classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction result on the sample comment is: pos\n"
     ]
    }
   ],
   "source": [
    "sample = [\"this movie is not good\"]\n",
    "sample_features  = tf_vec.transform(sample)\n",
    "sample_prediction = svm_model.predict(sample_features)[0]\n",
    "print (\"the prediction result on the sample comment is: \" + sample_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tf-idf + Logistic Regression\n",
    "\n",
    "Additional to NB and SVM, Logistic regression is also a linear, powerful and widely used model for classifying binary outputs.Logistic regression is a sigmoid function to estimate probabilities between positive or negative label y and data features x.\n",
    "\n",
    "In this section, we will start with train_features prepared in the SVM step and build a Logistic Regresssion model on it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tf-idf + Logistic Regression model trained in 0.436801 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "lgr_model = LogisticRegression()\n",
    "lgr_model.fit(train_features, train_y)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(\"Tf-idf + Logistic Regression model trained in %f seconds\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgr_model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.87664\n"
     ]
    }
   ],
   "source": [
    "accuracy = metrics.accuracy_score(pred,test_y)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        neg       0.88      0.87      0.88     12500\n",
      "        pos       0.87      0.88      0.88     12500\n",
      "\n",
      "avg / total       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true=test_y, y_pred=pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the prediction result on the sample comment is: neg\n"
     ]
    }
   ],
   "source": [
    "sample = [\"this movie is bad\"]\n",
    "sample_features  = tf_vec.transform(sample)\n",
    "sample_prediction = lgr_model.predict(sample_features)[0]\n",
    "print (\"the prediction result on the sample comment is: \" + sample_prediction)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be found that the Tf-idf + Logistic Regression model runs very fast (< 0.5 seconds), yet gives the best accurancy so far (88%). \n",
    "\n",
    "Although Naïve Bayes and Logistic regression are linear classifiers, Naïve Bayes is a generative classifier that tries\n",
    "to predict the likelihood term under the assumption of conditionally independent between features, however, this assumption less happened in the real word problems, but in contrast, Logistic regression is a discriminative classifier that use a Logistic function to get the likelihood directly. In addition, Logistic regression covers the case of a binary dependent variable. As our dataset are going to be classified in a positive and negative labels, it is expected to have better performance than Naïve Bayes and SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Word Embedding with Neural Network model\n",
    "\n",
    "Next, we will explore some of the advanced deep learning algorithms including Neural Networks and LSTM. \n",
    "\n",
    "This seciton will develop word embedding models for neural networks to classify movie reviews. it covers what is word embedding as part of fitting a deep learning model and how to use a pre-trained embedding in a neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to understand how deep learning can be applied, think about all the different forms of data that are used as inputs into machine learning or deep learning models. Instead of having a string input, we will need to convert each word in the comment in the sentence to a vector. The vector representation of a word is also known as a word embedding.\n",
    "\n",
    "#### load pre-trained word vectors\n",
    "In this part we will use pre-trained word embeddings, as opposed to having the system learn the word embeddings form our data. You can download pre-trained GloVe vectors from the [Stanford webpage](https://nlp.stanford.edu/projects/glove/). \n",
    "\n",
    "Unzipping the file, you will find pre-trained embeddings for various different dimensions. We will load the 50 dimension version in the file ‘glove.6B.50d.txt‘. \n",
    "\n",
    "Here, we’ll pass in words to an embedding layer. You can actually train up an embedding with word2vec and use it here. But it’s good enough to just have an embedding layer and let the network learn the embedding table on it’s own. \n",
    "\n",
    "In order to build the embedding layer, 2 dictionaries need to be loaded:\n",
    "\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.\n",
    "\n",
    "The reason we need `word_to_index` is that when adding a custom embedding layer in Keras, we can only load the pretrained embedding as a matrix instead of a dictionary. A index will help us find the correct entry for a given word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vec(glove_file):\n",
    "    with open(glove_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "        \n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            i = i + 1\n",
    "    return words_to_index, word_to_vec_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the 50 dimension version in the file ‘glove.6B.50d.txt‘\n",
    "_, word_to_vec_map = read_glove_vec('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load all of the training data movie reviews. For that, we can adapt the load_data() and preprocessing() from the previous section to load the csv documents, clean them, and return them as a list of strings. We want each document to be a string for easy encoding as a sequence of integers later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_data('train.csv')\n",
    "test_x, test_y = load_data('test.csv')\n",
    "train_x = [preprocessing(x) for x in train_x]\n",
    "test_x = [preprocessing(x) for x in test_x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to encode each document as a sequence of integers.The Keras Embedding layer requires integer inputs where each integer maps to a single token that has a specific real-valued vector representation within the embedding. We can encode the training documents as sequences of integers using the Tokenizer class in the Keras API.\n",
    "\n",
    "First, we must construct an instance of the class then train it on all documents in the training dataset. In this case, it develops a vocabulary of all tokens in the training dataset and develops a consistent mapping from words in the vocabulary to unique integers. We could just as easily develop this mapping ourselves using our vocabulary file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(train_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the mapping of words to integers has been prepared, we can use it to encode the reviews in both training and test dataset. We can do that by calling the texts_to_sequences() function on the Tokenizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence encode\n",
    "train_x_ec = tokenizer.texts_to_sequences(train_x)\n",
    "test_x_ec = tokenizer.texts_to_sequences(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After encoding the input features, we also need to encode the output value into binary for both train and test data: \n",
    "- binary encoding: \n",
    "    * pos --> 1\n",
    "    * neg --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "train_y_ec = np.array([0 if x == 'neg' else 1 for x in train_y])\n",
    "test_y_ec = np.array([0 if x == 'neg' else 1 for x in test_y])\n",
    "print(train_y_ec)\n",
    "print(test_y_ec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, We also need to ensure that all documents have the same length. This is a requirement of Keras for efficient computation. Since the reviews differ heavily in terms of lengths we need to have review samples to be the same length.  In this case, we will pad all reviews to 100. If reviews are shorter than the longest review,  we will pad them with zeros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# max_length = max([len(s.split()) for s in train_x])\n",
    "Xtrain = pad_sequences(train_x_ec, maxlen=100, padding='post')\n",
    "Xtest = pad_sequences(test_x_ec, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vocabulary size (largest integer value)\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the GloVe embedding and create the Embedding layer. The Glove file does not contain a header file, so we do not need to skip the first line when loading the embedding into memory. The updated load_embedding() function is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load embedding as a dict\n",
    "def load_embedding(filename):\n",
    "\t# load embedding into memory, skip first line\n",
    "\tfile = open(filename,'r',encoding='utf-8', errors='ignore')\n",
    "\tlines = file.readlines()\n",
    "\tfile.close()\n",
    "\t# create a map of words to vectors\n",
    "\tembedding = dict()\n",
    "\tfor line in lines:\n",
    "\t\tparts = line.split()\n",
    "\t\t# key is string word, value is numpy array for vector\n",
    "\t\tembedding[parts[0]] = np.asarray(parts[1:], dtype='float32')\n",
    "\treturn embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible that the loaded embedding does not contain all of the words in our chosen vocabulary. As such, when creating the Embedding weight matrix, we need to skip words that do not have a corresponding vector in the loaded GloVe data. Below is the updated, more defensive version of the get_weight_matrix() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import zeros\n",
    "\n",
    "# create a weight matrix for the Embedding layer from a loaded embedding\n",
    "def get_weight_matrix(embedding, vocab):\n",
    "\t# total vocabulary size plus 0 for unknown words\n",
    "\tvocab_size = len(vocab) + 1\n",
    "\t# define weight matrix dimensions with all 0\n",
    "\tweight_matrix = np.zeros((vocab_size, 50))\n",
    "\t# step vocab, store vectors using the Tokenizer's integer mapping\n",
    "\tfor word, i in vocab.items():\n",
    "\t\tvector = embedding.get(word)\n",
    "\t\tif vector is not None:\n",
    "\t\t\tweight_matrix[i] = vector\n",
    "\treturn weight_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the prepared weight matrix embedding_vectors is passed to the new Embedding layer as an argument and that we set the ‘trainable‘ argument to ‘False‘ to ensure that the network does not try to adapt the pre-learned vectors as part of training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "# load embedding from file\n",
    "raw_embedding = load_embedding('data/glove.6B.50d.txt')\n",
    "# get vectors in the right order\n",
    "embedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n",
    "# create the embedding layer\n",
    "embedding_layer = Embedding(vocab_size, 50, weights=[embedding_vectors], input_length=100, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now add this layer to our model. We also have a lot more filters (128) in the CNN model and a kernel that matches the 5 words used as neighbors when developing the word2vec embedding. Finally, the back-end of the model was simplified.\n",
    "\n",
    "- Steps of using Keras to build a neural network:\n",
    "    * Define the structure of the network.\n",
    "    * Print the summary of your network to see if shape and #of params is correct.\n",
    "    * Compile the model.\n",
    "    * Fit the model.\n",
    "    * Evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 100, 50)           3254100   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 96, 128)           32128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 48, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 6145      \n",
      "=================================================================\n",
      "Total params: 3,292,373\n",
      "Trainable params: 38,273\n",
      "Non-trainable params: 3,254,100\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      " - 16s - loss: 0.5310 - acc: 0.7372\n",
      "Epoch 2/100\n",
      " - 14s - loss: 0.4210 - acc: 0.8086\n",
      "Epoch 3/100\n",
      " - 14s - loss: 0.3429 - acc: 0.8563\n",
      "Epoch 4/100\n",
      " - 15s - loss: 0.2586 - acc: 0.8973\n",
      "Epoch 5/100\n",
      " - 14s - loss: 0.1894 - acc: 0.9316\n",
      "Epoch 6/100\n",
      " - 14s - loss: 0.1345 - acc: 0.9560\n",
      "Epoch 7/100\n",
      " - 14s - loss: 0.0921 - acc: 0.9739\n",
      "Epoch 8/100\n",
      " - 14s - loss: 0.0654 - acc: 0.9848\n",
      "Epoch 9/100\n",
      " - 13s - loss: 0.0450 - acc: 0.9914\n",
      "Epoch 10/100\n",
      " - 14s - loss: 0.0380 - acc: 0.9925\n",
      "Epoch 11/100\n",
      " - 14s - loss: 0.0336 - acc: 0.9919\n",
      "Epoch 12/100\n",
      " - 16s - loss: 0.0310 - acc: 0.9924\n",
      "Epoch 13/100\n",
      " - 15s - loss: 0.0191 - acc: 0.9973\n",
      "Epoch 14/100\n",
      " - 15s - loss: 0.0158 - acc: 0.9970\n",
      "Epoch 15/100\n",
      " - 15s - loss: 0.0195 - acc: 0.9958\n",
      "Epoch 16/100\n",
      " - 15s - loss: 0.0236 - acc: 0.9931\n",
      "Epoch 17/100\n",
      " - 14s - loss: 0.0259 - acc: 0.9918\n",
      "Epoch 18/100\n",
      " - 16s - loss: 0.0104 - acc: 0.9983\n",
      "Epoch 19/100\n",
      " - 15s - loss: 0.0073 - acc: 0.9990\n",
      "Epoch 20/100\n",
      " - 14s - loss: 0.0030 - acc: 0.9999\n",
      "Epoch 21/100\n",
      " - 14s - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 22/100\n",
      " - 14s - loss: 8.6678e-04 - acc: 1.0000\n",
      "Epoch 23/100\n",
      " - 14s - loss: 6.4791e-04 - acc: 1.0000\n",
      "Epoch 24/100\n",
      " - 15s - loss: 4.8785e-04 - acc: 1.0000\n",
      "Epoch 25/100\n",
      " - 14s - loss: 3.7549e-04 - acc: 1.0000\n",
      "Epoch 26/100\n",
      " - 15s - loss: 2.7801e-04 - acc: 1.0000\n",
      "Epoch 27/100\n",
      " - 13s - loss: 2.1174e-04 - acc: 1.0000\n",
      "Epoch 28/100\n",
      " - 14s - loss: 0.0501 - acc: 0.9865\n",
      "Epoch 29/100\n",
      " - 13s - loss: 0.0410 - acc: 0.9854\n",
      "Epoch 30/100\n",
      " - 14s - loss: 0.0116 - acc: 0.9966\n",
      "Epoch 31/100\n",
      " - 15s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 32/100\n",
      " - 15s - loss: 0.0010 - acc: 1.0000\n",
      "Epoch 33/100\n",
      " - 14s - loss: 5.4279e-04 - acc: 1.0000\n",
      "Epoch 34/100\n",
      " - 14s - loss: 3.9900e-04 - acc: 1.0000\n",
      "Epoch 35/100\n",
      " - 26s - loss: 3.0930e-04 - acc: 1.0000\n",
      "Epoch 36/100\n",
      " - 26s - loss: 2.4148e-04 - acc: 1.0000\n",
      "Epoch 37/100\n",
      " - 16s - loss: 1.9079e-04 - acc: 1.0000\n",
      "Epoch 38/100\n",
      " - 16s - loss: 1.4648e-04 - acc: 1.0000\n",
      "Epoch 39/100\n",
      " - 20s - loss: 1.1143e-04 - acc: 1.0000\n",
      "Epoch 40/100\n",
      " - 16s - loss: 8.4227e-05 - acc: 1.0000\n",
      "Epoch 41/100\n",
      " - 17s - loss: 6.3737e-05 - acc: 1.0000\n",
      "Epoch 42/100\n",
      " - 16s - loss: 4.8240e-05 - acc: 1.0000\n",
      "Epoch 43/100\n",
      " - 17s - loss: 3.5486e-05 - acc: 1.0000\n",
      "Epoch 44/100\n",
      " - 15s - loss: 9.8242e-05 - acc: 1.0000\n",
      "Epoch 45/100\n",
      " - 14s - loss: 0.0765 - acc: 0.9775\n",
      "Epoch 46/100\n",
      " - 14s - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 47/100\n",
      " - 14s - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 48/100\n",
      " - 14s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 49/100\n",
      " - 15s - loss: 3.5644e-04 - acc: 1.0000\n",
      "Epoch 50/100\n",
      " - 15s - loss: 1.9164e-04 - acc: 1.0000\n",
      "Epoch 51/100\n",
      " - 16s - loss: 1.4656e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      " - 14s - loss: 1.1528e-04 - acc: 1.0000\n",
      "Epoch 53/100\n",
      " - 15s - loss: 9.1417e-05 - acc: 1.0000\n",
      "Epoch 54/100\n",
      " - 15s - loss: 7.2745e-05 - acc: 1.0000\n",
      "Epoch 55/100\n",
      " - 14s - loss: 5.6647e-05 - acc: 1.0000\n",
      "Epoch 56/100\n",
      " - 14s - loss: 4.4396e-05 - acc: 1.0000\n",
      "Epoch 57/100\n",
      " - 14s - loss: 3.4503e-05 - acc: 1.0000\n",
      "Epoch 58/100\n",
      " - 14s - loss: 2.6625e-05 - acc: 1.0000\n",
      "Epoch 59/100\n",
      " - 15s - loss: 2.0035e-05 - acc: 1.0000\n",
      "Epoch 60/100\n",
      " - 15s - loss: 1.5018e-05 - acc: 1.0000\n",
      "Epoch 61/100\n",
      " - 14s - loss: 1.1612e-05 - acc: 1.0000\n",
      "Epoch 62/100\n",
      " - 15s - loss: 8.4994e-06 - acc: 1.0000\n",
      "Epoch 63/100\n",
      " - 15s - loss: 6.2335e-06 - acc: 1.0000\n",
      "Epoch 64/100\n",
      " - 14s - loss: 4.6072e-06 - acc: 1.0000\n",
      "Epoch 65/100\n",
      " - 14s - loss: 3.3843e-06 - acc: 1.0000\n",
      "Epoch 66/100\n",
      " - 14s - loss: 2.5186e-06 - acc: 1.0000\n",
      "Epoch 67/100\n",
      " - 14s - loss: 0.0102 - acc: 0.9980\n",
      "Epoch 68/100\n",
      " - 14s - loss: 0.0716 - acc: 0.9799\n",
      "Epoch 69/100\n",
      " - 14s - loss: 0.0173 - acc: 0.9942\n",
      "Epoch 70/100\n",
      " - 15s - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 71/100\n",
      " - 14s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 72/100\n",
      " - 14s - loss: 0.0068 - acc: 0.9978\n",
      "Epoch 73/100\n",
      " - 14s - loss: 0.0258 - acc: 0.9918\n",
      "Epoch 74/100\n",
      " - 14s - loss: 0.0236 - acc: 0.9924\n",
      "Epoch 75/100\n",
      " - 14s - loss: 0.0118 - acc: 0.9958\n",
      "Epoch 76/100\n",
      " - 14s - loss: 0.0080 - acc: 0.9970\n",
      "Epoch 77/100\n",
      " - 14s - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 78/100\n",
      " - 13s - loss: 0.0054 - acc: 0.9982\n",
      "Epoch 79/100\n",
      " - 14s - loss: 0.0253 - acc: 0.9911\n",
      "Epoch 80/100\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# define model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(embedding_layer)\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(MaxPooling1D(pool_size=2))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(1, activation='sigmoid'))\n",
    "print(cnn_model.summary())\n",
    "# compile network\n",
    "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit network\n",
    "cnn_model.fit(Xtrain, train_y_ec, epochs=100, verbose=2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Neural Network model trained in %f seconds\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate\n",
    "loss, acc = cnn_model.evaluate(Xtest, test_y_ec, verbose=2)\n",
    "print('Test Accuracy: %f' % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cnn_model.predict(Xtest, verbose=2)\n",
    "# covert pred into binary \n",
    "pred_test_y = [0 if y < 0.5 else 1 for y in pred]\n",
    "print(metrics.classification_report(y_true=test_y_ec, y_pred=pred_test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\"this movie is good\"]\n",
    "sample_ec = tokenizer.texts_to_sequences(sample)\n",
    "sample_ec_pad = pad_sequences(sample_ec, maxlen=100, padding='post')\n",
    "sample_prediction = cnn_model.predict(sample_ec_pad)\n",
    "result = \"neg\" if sample_prediction < 0.5 else \"pos\"\n",
    "print (\"the prediction result on the sample comment is: \" + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the example shows that performance was not improved.\n",
    "In fact, performance was a lot worse. The results show that the training dataset was learned successfully, but evaluation on the test dataset was very poor, at just above 75% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. LSTM (Long Short Term Memory)\n",
    "Long-Term Short Term Memory (LSTMs) are a type of network that has a memory that \"remembers\" previous data from the input and makes decisions based on that knowledge. These networks are more directly suited for written data inputs, since each word in a sentence has meaning based on the surrounding words (previous and upcoming words).\n",
    "\n",
    "In our particular case, it is possible that an LSTM could allow us to capture changing sentiment in a comment. The LSTM can learn that sentiments expressed towards the end of a sentence mean more than those expressed at the start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, word_to_vec_map = read_glove_vec('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "# create the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "# fit the tokenizer on the documents\n",
    "tokenizer.fit_on_texts(train_x)\n",
    "# sequence encode\n",
    "train_x_ec = tokenizer.texts_to_sequences(train_x)\n",
    "test_x_ec = tokenizer.texts_to_sequences(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "Xtrain = pad_sequences(train_x_ec, maxlen=100, padding='post')\n",
    "Xtest = pad_sequences(test_x_ec, maxlen=100, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, SpatialDropout1D\n",
    "# load embedding from file\n",
    "raw_embedding = load_embedding('data/glove.6B.50d.txt')\n",
    "# get vectors in the right order\n",
    "embedding_vectors = get_weight_matrix(raw_embedding, tokenizer.word_index)\n",
    "# create the embedding layer\n",
    "embedding_layer = Embedding(vocab_size, 50, weights=[embedding_vectors], input_length=100, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build a LSTM model that receives the processed embedding_layer with vectorized words as input to generate prediction. Our model is composed of the embedding layer as input, a single LSTM layer, a dense layer with tanh activation followed by a logistic regression layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = Sequential()\n",
    "lstm_model.add(embedding_layer)\n",
    "lstm_model.add(SpatialDropout1D(0.4))\n",
    "lstm_model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "lstm_model.add(Dense(20, activation='tanh'))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "end = time.time()\n",
    "print(\"Neural Network model trained in %f seconds\" % (end-start))print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = lstm_model.fit(Xtrain, train_y_ec, batch_size=32, epochs = 300, verbose = 2)\n",
    "\n",
    "end = time.time()\n",
    "print(\"LSTM model trained in %f seconds\" % (end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score,acc = lstm_model.evaluate(Xtest, test_y_ec, verbose = 2, batch_size = 32)\n",
    "print(\"score: %.2f\" % (score))\n",
    "print(\"acc: %.2f\" % (acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lstm_model.predict(Xtest)\n",
    "pred_test_y = [0 if y < 0.5 else 1 for y in pred]\n",
    "print(metrics.classification_report(y_true=test_y_ec, y_pred=pred_test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be found that the LSTM model provides 87% accurancy, much better than NB, SVM, and CNN but still 1% less than Tf-Idf LR model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = history.history.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [\"this movie is not good\"]\n",
    "sample_ec = tokenizer.texts_to_sequences(sample)\n",
    "sample_ec_pad = pad_sequences(sample_ec, maxlen=100, padding='post')\n",
    "sample_prediction = lstm_model.predict(sample_ec_pad)\n",
    "result = \"neg\" if sample_prediction < 0.5 else \"pos\"\n",
    "print (\"the prediction result on the sample comment is: \" + result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the history curves above, it seems that the model's training is going well. The loss is decreasing steadily, and the accuracy is increasing gradually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "In this notebook, we went over the entire process to build an automatic sentiment analysis using advanced machine learning and deep learning models including NB, SVM, Logistic Regression, Neural Network, LSTM. We introduced different components involved in the whole pipeline and have evaluated and compared our model performance.  \n",
    "\n",
    "Comparing the different models built before, it can be found that the logistic regression gives the best accurancy with very fast training. The advanced deep learning algorithms (CNN and LSTM) doesn't provide better performance than linear models. One possible explanation for the poor performance might cause by the small size of the dataset (25K), where CNN and RNN should perform better with larger set of training data ( > millions)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
